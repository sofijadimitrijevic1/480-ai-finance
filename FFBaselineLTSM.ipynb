{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -q kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset not found locally - downloading via kagglehub...\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.1).\n",
      "Using dataset directory: /Users/glennc/.cache/kagglehub/datasets/computingvictor/transactions-fraud-datasets/versions/1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10649266</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23410063</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9316588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12478022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9558530</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  transaction_id  target\n",
       "0       10649266       0\n",
       "1       23410063       0\n",
       "2        9316588       0\n",
       "3       12478022       0\n",
       "4        9558530       0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "\n",
    "DATASET_ID = \"computingvictor/transactions-fraud-datasets\"\n",
    "DATASET_FOLDER_NAME = \"transactions-fraud-datasets\"\n",
    "\n",
    "def find_repo_root():\n",
    "    cur = Path.cwd().resolve()\n",
    "    for p in [cur] + list(cur.parents):\n",
    "        if (p / \".git\").exists():\n",
    "            return p\n",
    "    return cur\n",
    "\n",
    "def resolve_dataset_dir():\n",
    "    # 1) Environment variable override\n",
    "    env = os.getenv(\"FRAUD_DATA_DIR\")\n",
    "    if env:\n",
    "        p = Path(env).expanduser().resolve()\n",
    "        if p.exists():\n",
    "            return p\n",
    "\n",
    "    # 2) Repo-relative data folder\n",
    "    repo_root = find_repo_root()\n",
    "    local = repo_root / \"data\" / DATASET_FOLDER_NAME\n",
    "    if local.exists():\n",
    "        return local.resolve()\n",
    "\n",
    "    # 3) Auto-download via kagglehub\n",
    "    print(\"Dataset not found locally - downloading via kagglehub...\")\n",
    "    return Path(kagglehub.dataset_download(DATASET_ID)).resolve()\n",
    "\n",
    "dataset_dir = resolve_dataset_dir()\n",
    "print(\"Using dataset directory:\", dataset_dir)\n",
    "\n",
    "tx_path = dataset_dir / \"transactions_data.csv\"\n",
    "labels_path = dataset_dir / \"train_fraud_labels.json\"\n",
    "\n",
    "assert tx_path.exists(), f\"Missing {tx_path}\"\n",
    "assert labels_path.exists(), f\"Missing {labels_path}\"\n",
    "\n",
    "with open(labels_path, \"r\") as f:\n",
    "    labels_raw = json.load(f)\n",
    "\n",
    "target_map = labels_raw[\"target\"]  # dict: transaction_id -> \"Yes\"/\"No\"\n",
    "\n",
    "labels = pd.DataFrame({\n",
    "    \"transaction_id\": list(target_map.keys()),\n",
    "    \"target\": [1 if v == \"Yes\" else 0 for v in target_map.values()]\n",
    "})\n",
    "\n",
    "labels[\"transaction_id\"] = labels[\"transaction_id\"].astype(str)\n",
    "labels[\"target\"] = labels[\"target\"].astype(int)\n",
    "\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset transactions: (3358392, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>client_id</th>\n",
       "      <th>card_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>use_chip</th>\n",
       "      <th>merchant_state</th>\n",
       "      <th>mcc</th>\n",
       "      <th>errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7475328</td>\n",
       "      <td>2010-01-01 00:02:00</td>\n",
       "      <td>561</td>\n",
       "      <td>4575</td>\n",
       "      <td>$14.57</td>\n",
       "      <td>Swipe Transaction</td>\n",
       "      <td>IA</td>\n",
       "      <td>5311</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7475329</td>\n",
       "      <td>2010-01-01 00:02:00</td>\n",
       "      <td>1129</td>\n",
       "      <td>102</td>\n",
       "      <td>$80.00</td>\n",
       "      <td>Swipe Transaction</td>\n",
       "      <td>CA</td>\n",
       "      <td>4829</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7475333</td>\n",
       "      <td>2010-01-01 00:07:00</td>\n",
       "      <td>1807</td>\n",
       "      <td>165</td>\n",
       "      <td>$4.81</td>\n",
       "      <td>Swipe Transaction</td>\n",
       "      <td>NY</td>\n",
       "      <td>5942</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7475337</td>\n",
       "      <td>2010-01-01 00:21:00</td>\n",
       "      <td>351</td>\n",
       "      <td>1112</td>\n",
       "      <td>$10.74</td>\n",
       "      <td>Swipe Transaction</td>\n",
       "      <td>NY</td>\n",
       "      <td>5813</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7475344</td>\n",
       "      <td>2010-01-01 00:32:00</td>\n",
       "      <td>646</td>\n",
       "      <td>2093</td>\n",
       "      <td>$73.79</td>\n",
       "      <td>Swipe Transaction</td>\n",
       "      <td>PA</td>\n",
       "      <td>7538</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                 date  client_id  card_id  amount  \\\n",
       "0  7475328  2010-01-01 00:02:00        561     4575  $14.57   \n",
       "1  7475329  2010-01-01 00:02:00       1129      102  $80.00   \n",
       "2  7475333  2010-01-01 00:07:00       1807      165   $4.81   \n",
       "3  7475337  2010-01-01 00:21:00        351     1112  $10.74   \n",
       "4  7475344  2010-01-01 00:32:00        646     2093  $73.79   \n",
       "\n",
       "            use_chip merchant_state   mcc errors  \n",
       "0  Swipe Transaction             IA  5311    NaN  \n",
       "1  Swipe Transaction             CA  4829    NaN  \n",
       "2  Swipe Transaction             NY  5942    NaN  \n",
       "3  Swipe Transaction             NY  5813    NaN  \n",
       "4  Swipe Transaction             PA  7538    NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "usecols = [\n",
    "    \"id\", \"date\", \"client_id\", \"card_id\", \"amount\",\n",
    "    \"use_chip\", \"merchant_state\", \"mcc\", \"errors\"\n",
    "]\n",
    "\n",
    "# Choose clients from an early slice of the dataset\n",
    "first_chunk = pd.read_csv(tx_path, usecols=[\"client_id\"], nrows=200_000)\n",
    "clients = first_chunk[\"client_id\"].dropna().unique()\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "N_CLIENTS = 300   \n",
    "chosen_clients = set(np.random.choice(clients, size=min(N_CLIENTS, len(clients)), replace=False))\n",
    "\n",
    "chunks = []\n",
    "for chunk in pd.read_csv(tx_path, usecols=usecols, chunksize=200_000):\n",
    "    keep = chunk[chunk[\"client_id\"].isin(chosen_clients)]\n",
    "    if len(keep):\n",
    "        chunks.append(keep)\n",
    "\n",
    "tx = pd.concat(chunks, ignore_index=True)\n",
    "tx[\"id\"] = tx[\"id\"].astype(str)\n",
    "\n",
    "print(\"Subset transactions:\", tx.shape)\n",
    "tx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 3358392\n",
      "Labeled rows: 2249957\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>client_id</th>\n",
       "      <th>card_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>use_chip</th>\n",
       "      <th>merchant_state</th>\n",
       "      <th>mcc</th>\n",
       "      <th>errors</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7475328</td>\n",
       "      <td>2010-01-01 00:02:00</td>\n",
       "      <td>561</td>\n",
       "      <td>4575</td>\n",
       "      <td>$14.57</td>\n",
       "      <td>Swipe Transaction</td>\n",
       "      <td>IA</td>\n",
       "      <td>5311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7475329</td>\n",
       "      <td>2010-01-01 00:02:00</td>\n",
       "      <td>1129</td>\n",
       "      <td>102</td>\n",
       "      <td>$80.00</td>\n",
       "      <td>Swipe Transaction</td>\n",
       "      <td>CA</td>\n",
       "      <td>4829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7475333</td>\n",
       "      <td>2010-01-01 00:07:00</td>\n",
       "      <td>1807</td>\n",
       "      <td>165</td>\n",
       "      <td>$4.81</td>\n",
       "      <td>Swipe Transaction</td>\n",
       "      <td>NY</td>\n",
       "      <td>5942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7475337</td>\n",
       "      <td>2010-01-01 00:21:00</td>\n",
       "      <td>351</td>\n",
       "      <td>1112</td>\n",
       "      <td>$10.74</td>\n",
       "      <td>Swipe Transaction</td>\n",
       "      <td>NY</td>\n",
       "      <td>5813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7475344</td>\n",
       "      <td>2010-01-01 00:32:00</td>\n",
       "      <td>646</td>\n",
       "      <td>2093</td>\n",
       "      <td>$73.79</td>\n",
       "      <td>Swipe Transaction</td>\n",
       "      <td>PA</td>\n",
       "      <td>7538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                 date  client_id  card_id  amount  \\\n",
       "0  7475328  2010-01-01 00:02:00        561     4575  $14.57   \n",
       "1  7475329  2010-01-01 00:02:00       1129      102  $80.00   \n",
       "2  7475333  2010-01-01 00:07:00       1807      165   $4.81   \n",
       "3  7475337  2010-01-01 00:21:00        351     1112  $10.74   \n",
       "4  7475344  2010-01-01 00:32:00        646     2093  $73.79   \n",
       "\n",
       "            use_chip merchant_state   mcc errors  target  \n",
       "0  Swipe Transaction             IA  5311    NaN     0.0  \n",
       "1  Swipe Transaction             CA  4829    NaN     0.0  \n",
       "2  Swipe Transaction             NY  5942    NaN     0.0  \n",
       "3  Swipe Transaction             NY  5813    NaN     NaN  \n",
       "4  Swipe Transaction             PA  7538    NaN     0.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx[\"id\"] = tx[\"id\"].astype(str)\n",
    "\n",
    "tx = tx.merge(labels, left_on=\"id\", right_on=\"transaction_id\", how=\"left\")\n",
    "tx = tx.drop(columns=[\"transaction_id\"])\n",
    "\n",
    "print(\"Rows:\", len(tx))\n",
    "print(\"Labeled rows:\", tx[\"target\"].notna().sum())\n",
    "tx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>client_id</th>\n",
       "      <th>card_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>use_chip</th>\n",
       "      <th>merchant_state</th>\n",
       "      <th>mcc</th>\n",
       "      <th>errors</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7477094</td>\n",
       "      <td>2010-01-01 11:58:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4652</td>\n",
       "      <td>15.09</td>\n",
       "      <td>Swipe Transaction</td>\n",
       "      <td>FL</td>\n",
       "      <td>4121</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7477168</td>\n",
       "      <td>2010-01-01 12:11:00</td>\n",
       "      <td>1</td>\n",
       "      <td>3682</td>\n",
       "      <td>6.01</td>\n",
       "      <td>Swipe Transaction</td>\n",
       "      <td>FL</td>\n",
       "      <td>5813</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7477216</td>\n",
       "      <td>2010-01-01 12:18:00</td>\n",
       "      <td>1</td>\n",
       "      <td>3682</td>\n",
       "      <td>14.58</td>\n",
       "      <td>Online Transaction</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>4121</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7477978</td>\n",
       "      <td>2010-01-01 15:09:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4652</td>\n",
       "      <td>14.66</td>\n",
       "      <td>Online Transaction</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>4121</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7478279</td>\n",
       "      <td>2010-01-01 16:26:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4652</td>\n",
       "      <td>22.77</td>\n",
       "      <td>Swipe Transaction</td>\n",
       "      <td>FL</td>\n",
       "      <td>4121</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                date  client_id  card_id  amount  \\\n",
       "0  7477094 2010-01-01 11:58:00          1     4652   15.09   \n",
       "1  7477168 2010-01-01 12:11:00          1     3682    6.01   \n",
       "2  7477216 2010-01-01 12:18:00          1     3682   14.58   \n",
       "3  7477978 2010-01-01 15:09:00          1     4652   14.66   \n",
       "4  7478279 2010-01-01 16:26:00          1     4652   22.77   \n",
       "\n",
       "             use_chip merchant_state   mcc errors  target  \n",
       "0   Swipe Transaction             FL  4121   None     0.0  \n",
       "1   Swipe Transaction             FL  5813   None     0.0  \n",
       "2  Online Transaction        Unknown  4121   None     0.0  \n",
       "3  Online Transaction        Unknown  4121   None     0.0  \n",
       "4   Swipe Transaction             FL  4121   None     NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx[\"date\"] = pd.to_datetime(tx[\"date\"], errors=\"coerce\")\n",
    "tx = tx.dropna(subset=[\"date\"])\n",
    "\n",
    "def parse_amount(x):\n",
    "    x = str(x).replace(\"$\",\"\").replace(\",\",\"\").strip()\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "tx[\"amount\"] = tx[\"amount\"].apply(parse_amount)\n",
    "tx = tx.dropna(subset=[\"amount\"])\n",
    "\n",
    "# Fill missing categoricals\n",
    "tx[\"errors\"] = tx[\"errors\"].fillna(\"None\").astype(str)\n",
    "tx[\"use_chip\"] = tx[\"use_chip\"].fillna(\"Unknown\").astype(str)\n",
    "tx[\"merchant_state\"] = tx[\"merchant_state\"].fillna(\"Unknown\").astype(str)\n",
    "tx[\"mcc\"] = tx[\"mcc\"].fillna(-1).astype(int).astype(str)  # treat as categorical\n",
    "\n",
    "# Sort per client\n",
    "tx = tx.sort_values([\"client_id\", \"date\"]).reset_index(drop=True)\n",
    "\n",
    "tx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2350739, 503758, 503895)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def time_split(df, client_col=\"client_id\", frac_train=0.70, frac_val=0.15, min_len=20):\n",
    "    train_idx, val_idx, test_idx = [], [], []\n",
    "    for cid, g in df.groupby(client_col, sort=False):\n",
    "        n = len(g)\n",
    "        if n < min_len:\n",
    "            continue\n",
    "        t1 = int(n * frac_train)\n",
    "        t2 = int(n * (frac_train + frac_val))\n",
    "        idx = g.index.to_numpy()\n",
    "        train_idx.append(idx[:t1])\n",
    "        val_idx.append(idx[t1:t2])\n",
    "        test_idx.append(idx[t2:])\n",
    "    return np.concatenate(train_idx), np.concatenate(val_idx), np.concatenate(test_idx)\n",
    "\n",
    "train_idx, val_idx, test_idx = time_split(tx)\n",
    "\n",
    "train_df = tx.loc[train_idx].copy()\n",
    "val_df   = tx.loc[val_idx].copy()\n",
    "test_df  = tx.loc[test_idx].copy()\n",
    "\n",
    "len(train_df), len(val_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2350739, 7)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "\n",
    "for d in [train_df, val_df, test_df]:\n",
    "    d[\"hour\"] = d[\"date\"].dt.hour\n",
    "    d[\"dayofweek\"] = d[\"date\"].dt.dayofweek\n",
    "\n",
    "num_cols = [\"amount\", \"hour\", \"dayofweek\"]\n",
    "cat_cols = [\"use_chip\", \"merchant_state\", \"mcc\", \"errors\"]\n",
    "\n",
    "enc = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "Xtr_cat = enc.fit_transform(train_df[cat_cols])\n",
    "Xva_cat = enc.transform(val_df[cat_cols])\n",
    "Xte_cat = enc.transform(test_df[cat_cols])\n",
    "\n",
    "Xtr_num = scaler.fit_transform(train_df[num_cols])\n",
    "Xva_num = scaler.transform(val_df[num_cols])\n",
    "Xte_num = scaler.transform(test_df[num_cols])\n",
    "\n",
    "X_train = np.hstack([Xtr_num, Xtr_cat]).astype(np.float32)\n",
    "X_val   = np.hstack([Xva_num, Xva_cat]).astype(np.float32)\n",
    "X_test  = np.hstack([Xte_num, Xte_cat]).astype(np.float32)\n",
    "\n",
    "y_train = train_df[\"target\"].to_numpy()\n",
    "y_val   = val_df[\"target\"].to_numpy()\n",
    "y_test  = test_df[\"target\"].to_numpy()\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 10, 7), np.float64(0.0018))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_sequences_sampled(df_part, X_part, y_part, seq_len=10, max_windows=50_000, client_col=\"client_id\"):\n",
    "    X_seqs = np.zeros((max_windows, seq_len, X_part.shape[1]), dtype=np.float32)\n",
    "    y_seqs = np.zeros((max_windows,), dtype=np.int64)\n",
    "\n",
    "    k = 0\n",
    "    start = 0\n",
    "    rng = np.random.default_rng(0)\n",
    "\n",
    "    for cid, g in df_part.groupby(client_col, sort=False):\n",
    "        n = len(g)\n",
    "        if n <= seq_len:\n",
    "            start += n\n",
    "            continue\n",
    "\n",
    "        Xg = X_part[start:start+n]\n",
    "        yg = y_part[start:start+n]\n",
    "\n",
    "        # indices where label exists and we have enough history\n",
    "        valid_t = np.where(~np.isnan(yg))[0]\n",
    "        valid_t = valid_t[valid_t >= seq_len]\n",
    "        if len(valid_t) == 0:\n",
    "            start += n\n",
    "            continue\n",
    "\n",
    "        # sample up to some per client (keeps balance and speed)\n",
    "        take = min(len(valid_t), 50)\n",
    "        chosen = rng.choice(valid_t, size=take, replace=False)\n",
    "\n",
    "        for t in chosen:\n",
    "            if k >= max_windows:\n",
    "                return X_seqs[:k], y_seqs[:k]\n",
    "            X_seqs[k] = Xg[t-seq_len:t]\n",
    "            y_seqs[k] = int(yg[t])\n",
    "            k += 1\n",
    "\n",
    "        start += n\n",
    "\n",
    "    return X_seqs[:k], y_seqs[:k]\n",
    "\n",
    "\n",
    "SEQ_LEN = 10\n",
    "Xtr_seq, ytr_seq = build_sequences_sampled(train_df, X_train, y_train, seq_len=SEQ_LEN, max_windows=50_000)\n",
    "Xva_seq, yva_seq = build_sequences_sampled(val_df, X_val, y_val, seq_len=SEQ_LEN, max_windows=20_000)\n",
    "Xte_seq, yte_seq = build_sequences_sampled(test_df,  X_test,  y_test,  seq_len=SEQ_LEN)\n",
    "\n",
    "Xtr_seq.shape, ytr_seq.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/glennc/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/glennc/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/glennc/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/glennc/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/glennc/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/glennc/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/glennc/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/glennc/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/glennc/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/glennc/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/glennc/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/glennc/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/glennc/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg best threshold (val): 0.99 | val metrics: {'precision': 0.002398081534772182, 'recall': 0.06666666666666667, 'f1': 0.004629629629629629, 'fpr': np.float64(0.027761094427761094), 'roc_auc': np.float64(0.5006161717272828), 'pr_auc': np.float64(0.0012614757612957484)}\n",
      "RF best threshold (val): 0.01 | val metrics: {'precision': 0.000945179584120983, 'recall': 0.06666666666666667, 'f1': 0.001863932898415657, 'fpr': np.float64(0.0705372038705372), 'roc_auc': np.float64(0.5373462351240129), 'pr_auc': np.float64(0.0011903203970417913)}\n"
     ]
    }
   ],
   "source": [
    "# Non-Neural Baseline Models (for comparison with LSTM)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, average_precision_score\n",
    "\n",
    "# Flatten LSTM windows for sklearn baselines: (N, seq_len, feat) -> (N, seq_len*feat)\n",
    "Xtr_flat = Xtr_seq.reshape(Xtr_seq.shape[0], -1)\n",
    "Xva_flat = Xva_seq.reshape(Xva_seq.shape[0], -1)\n",
    "Xte_flat = Xte_seq.reshape(Xte_seq.shape[0], -1)\n",
    "\n",
    "ytr = ytr_seq.astype(int)\n",
    "yva = yva_seq.astype(int)\n",
    "yte = yte_seq.astype(int)\n",
    "\n",
    "def compute_metrics(y_true, y_prob, threshold=0.5):\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"binary\", zero_division=0\n",
    "    )\n",
    "    fpr = ((y_pred == 1) & (y_true == 0)).sum() / max((y_true == 0).sum(), 1)\n",
    "\n",
    "    roc = roc_auc_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else np.nan\n",
    "    pr  = average_precision_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else np.nan\n",
    "    return {\"precision\": prec, \"recall\": rec, \"f1\": f1, \"fpr\": fpr, \"roc_auc\": roc, \"pr_auc\": pr}\n",
    "\n",
    "def best_threshold_f1(y_true, y_prob, thresholds=None):\n",
    "    if thresholds is None:\n",
    "        thresholds = np.linspace(0.01, 0.99, 99)\n",
    "    best_t, best_f1, best_m = 0.5, -1, None\n",
    "    for t in thresholds:\n",
    "        m = compute_metrics(y_true, y_prob, threshold=t)\n",
    "        if m[\"f1\"] > best_f1:\n",
    "            best_f1, best_t, best_m = m[\"f1\"], t, m\n",
    "    return best_t, best_m\n",
    "\n",
    "# --- Train baseline models (store probs so we can compare later) ---\n",
    "baseline_results = {}\n",
    "\n",
    "# Logistic Regression baseline\n",
    "logreg = LogisticRegression(max_iter=2000, class_weight=\"balanced\", n_jobs=-1)\n",
    "logreg.fit(Xtr_flat, ytr)\n",
    "\n",
    "va_prob_lr = logreg.predict_proba(Xva_flat)[:, 1]\n",
    "best_t_lr, va_metrics_lr = best_threshold_f1(yva, va_prob_lr)\n",
    "te_prob_lr = logreg.predict_proba(Xte_flat)[:, 1]\n",
    "te_metrics_lr = compute_metrics(yte, te_prob_lr, threshold=best_t_lr)\n",
    "\n",
    "baseline_results[\"LogReg\"] = {\n",
    "    \"val_prob\": va_prob_lr, \"test_prob\": te_prob_lr,\n",
    "    \"best_t\": best_t_lr,\n",
    "    \"val\": va_metrics_lr, \"test\": te_metrics_lr\n",
    "}\n",
    "\n",
    "print(\"LogReg best threshold (val):\", best_t_lr, \"| val metrics:\", va_metrics_lr)\n",
    "\n",
    "# Random Forest baseline (optional; can be slower)\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300, min_samples_leaf=2,\n",
    "    class_weight=\"balanced_subsample\",\n",
    "    n_jobs=-1, random_state=0\n",
    ")\n",
    "rf.fit(Xtr_flat, ytr)\n",
    "\n",
    "va_prob_rf = rf.predict_proba(Xva_flat)[:, 1]\n",
    "best_t_rf, va_metrics_rf = best_threshold_f1(yva, va_prob_rf)\n",
    "te_prob_rf = rf.predict_proba(Xte_flat)[:, 1]\n",
    "te_metrics_rf = compute_metrics(yte, te_prob_rf, threshold=best_t_rf)\n",
    "\n",
    "baseline_results[\"RandomForest\"] = {\n",
    "    \"val_prob\": va_prob_rf, \"test_prob\": te_prob_rf,\n",
    "    \"best_t\": best_t_rf,\n",
    "    \"val\": va_metrics_rf, \"test\": te_metrics_rf\n",
    "}\n",
    "\n",
    "print(\"RF best threshold (val):\", best_t_rf, \"| val metrics:\", va_metrics_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X)         \n",
    "        self.y = torch.from_numpy(y).float() \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n",
    "batch_size = 128  \n",
    "train_loader = DataLoader(SeqDataset(Xtr_seq, ytr_seq), batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(SeqDataset(Xva_seq, yva_seq), batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(SeqDataset(Xte_seq, yte_seq), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "class FraudLSTM(nn.Module):\n",
    "    def __init__(self, num_features, hidden_size=64):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=num_features, hidden_size=hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        return self.fc(h_n[-1]).squeeze(1)  # logits\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = FraudLSTM(num_features=Xtr_seq.shape[2], hidden_size=64).to(device)\n",
    "\n",
    "pos = ytr_seq.sum()\n",
    "neg = len(ytr_seq) - pos\n",
    "pos_weight = torch.tensor([neg / max(pos, 1)], dtype=torch.float32).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | loss=1.3019 | val={'precision': 0.0009150805270863836, 'recall': 0.3333333333333333, 'f1': 0.001825150574922431, 'fpr': np.float64(0.3642976309642976), 'roc_auc': np.float64(0.46177288399510624), 'pr_auc': np.float64(0.0009387279380285513)}\n",
      "Epoch 2 | loss=1.2204 | val={'precision': 0.0010991426687183997, 'recall': 0.3333333333333333, 'f1': 0.0021910604732690623, 'fpr': np.float64(0.30323656990323655), 'roc_auc': np.float64(0.5143187632076521), 'pr_auc': np.float64(0.0025743289628410485)}\n",
      "Epoch 3 | loss=1.2136 | val={'precision': 0.0009924573243350536, 'recall': 0.3333333333333333, 'f1': 0.0019790223629527013, 'fpr': np.float64(0.3358692025358692), 'roc_auc': np.float64(0.5233233233233233), 'pr_auc': np.float64(0.0019407854736534019)}\n",
      "Epoch 4 | loss=1.1478 | val={'precision': 0.00121921482565228, 'recall': 0.3333333333333333, 'f1': 0.0024295432458697765, 'fpr': np.float64(0.27334000667334), 'roc_auc': np.float64(0.5008252697141586), 'pr_auc': np.float64(0.0011879941812983335)}\n",
      "Epoch 5 | loss=1.1672 | val={'precision': 0.001392434439545138, 'recall': 0.4, 'f1': 0.0027752081406105457, 'fpr': np.float64(0.2871538204871538), 'roc_auc': np.float64(0.562228895562229), 'pr_auc': np.float64(0.0017542336359278445)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, average_precision_score\n",
    "\n",
    "def eval_model(model, loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_y, all_p = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            probs = torch.sigmoid(model(xb)).cpu().numpy()\n",
    "            all_p.append(probs)\n",
    "            all_y.append(yb.numpy())\n",
    "\n",
    "    y_true = np.concatenate(all_y).astype(int)\n",
    "    y_prob = np.concatenate(all_p)\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\", zero_division=0)\n",
    "    fpr = ((y_pred == 1) & (y_true == 0)).sum() / max((y_true == 0).sum(), 1)\n",
    "\n",
    "    roc = roc_auc_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else np.nan\n",
    "    pr_auc = average_precision_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else np.nan\n",
    "\n",
    "    return {\"precision\": prec, \"recall\": rec, \"f1\": f1, \"fpr\": fpr, \"roc_auc\": roc, \"pr_auc\": pr_auc}\n",
    "\n",
    "def train_epochs(model, epochs=5):\n",
    "    best_f1, best_state = -1, None\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(xb), yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * len(yb)\n",
    "\n",
    "        val_metrics = eval_model(model, val_loader)\n",
    "        print(f\"Epoch {epoch} | loss={total_loss/len(train_loader.dataset):.4f} | val={val_metrics}\")\n",
    "\n",
    "        if val_metrics[\"f1\"] > best_f1:\n",
    "            best_f1 = val_metrics[\"f1\"]\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "    if best_state:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "train_epochs(model, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>split</th>\n",
       "      <th>best_threshold_from_val</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>fpr</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>pr_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>test</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>0.010552</td>\n",
       "      <td>0.411511</td>\n",
       "      <td>0.002087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>val</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.010277</td>\n",
       "      <td>0.562229</td>\n",
       "      <td>0.001754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>test</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.004338</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.030655</td>\n",
       "      <td>0.515080</td>\n",
       "      <td>0.002514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>val</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.004630</td>\n",
       "      <td>0.027761</td>\n",
       "      <td>0.500616</td>\n",
       "      <td>0.001261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>test</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.003929</td>\n",
       "      <td>0.066052</td>\n",
       "      <td>0.521660</td>\n",
       "      <td>0.002157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>val</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.070537</td>\n",
       "      <td>0.537346</td>\n",
       "      <td>0.001190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model split  best_threshold_from_val  precision    recall        f1  \\\n",
       "5          LSTM  test                     0.73   0.006289  0.037037  0.010753   \n",
       "4          LSTM   val                     0.73   0.006452  0.066667  0.011765   \n",
       "1        LogReg  test                     0.99   0.004338  0.074074  0.008197   \n",
       "0        LogReg   val                     0.99   0.002398  0.066667  0.004630   \n",
       "3  RandomForest  test                     0.01   0.002018  0.074074  0.003929   \n",
       "2  RandomForest   val                     0.01   0.000945  0.066667  0.001864   \n",
       "\n",
       "        fpr   roc_auc    pr_auc  \n",
       "5  0.010552  0.411511  0.002087  \n",
       "4  0.010277  0.562229  0.001754  \n",
       "1  0.030655  0.515080  0.002514  \n",
       "0  0.027761  0.500616  0.001261  \n",
       "3  0.066052  0.521660  0.002157  \n",
       "2  0.070537  0.537346  0.001190  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, average_precision_score\n",
    "\n",
    "def get_probs_from_loader(model, loader, device):\n",
    "    model.eval()\n",
    "    all_y, all_prob = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            prob = torch.sigmoid(model(xb)).cpu().numpy()\n",
    "            all_prob.append(prob)\n",
    "            all_y.append(yb.numpy())\n",
    "    return np.concatenate(all_y).astype(int), np.concatenate(all_prob)\n",
    "\n",
    "def compute_metrics(y_true, y_prob, threshold=0.5):\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"binary\", zero_division=0\n",
    "    )\n",
    "    fpr = ((y_pred == 1) & (y_true == 0)).sum() / max((y_true == 0).sum(), 1)\n",
    "    roc = roc_auc_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else np.nan\n",
    "    pr  = average_precision_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else np.nan\n",
    "    return {\"precision\": prec, \"recall\": rec, \"f1\": f1, \"fpr\": fpr, \"roc_auc\": roc, \"pr_auc\": pr}\n",
    "\n",
    "def best_threshold_f1(y_true, y_prob, thresholds=None):\n",
    "    if thresholds is None:\n",
    "        thresholds = np.linspace(0.01, 0.99, 99)\n",
    "    best_t, best_f1, best_m = 0.5, -1, None\n",
    "    for t in thresholds:\n",
    "        m = compute_metrics(y_true, y_prob, threshold=t)\n",
    "        if m[\"f1\"] > best_f1:\n",
    "            best_f1, best_t, best_m = m[\"f1\"], t, m\n",
    "    return best_t, best_m\n",
    "\n",
    "# ---- LSTM metrics ----\n",
    "yva_true_lstm, yva_prob_lstm = get_probs_from_loader(model, val_loader, device)\n",
    "best_t_lstm, va_metrics_lstm = best_threshold_f1(yva_true_lstm, yva_prob_lstm)\n",
    "\n",
    "yte_true_lstm, yte_prob_lstm = get_probs_from_loader(model, test_loader, device)\n",
    "te_metrics_lstm = compute_metrics(yte_true_lstm, yte_prob_lstm, threshold=best_t_lstm)\n",
    "\n",
    "# ---- Build comparison table ----\n",
    "rows = []\n",
    "\n",
    "def add_row(name, best_t, split, metrics):\n",
    "    rows.append({\n",
    "        \"model\": name,\n",
    "        \"split\": split,\n",
    "        \"best_threshold_from_val\": best_t,\n",
    "        **metrics\n",
    "    })\n",
    "\n",
    "# baselines (from Cell A)\n",
    "for name, info in baseline_results.items():\n",
    "    add_row(name, info[\"best_t\"], \"val\",  info[\"val\"])\n",
    "    add_row(name, info[\"best_t\"], \"test\", info[\"test\"])\n",
    "\n",
    "# LSTM\n",
    "add_row(\"LSTM\", best_t_lstm, \"val\",  va_metrics_lstm)\n",
    "add_row(\"LSTM\", best_t_lstm, \"test\", te_metrics_lstm)\n",
    "\n",
    "df_compare = pd.DataFrame(rows)\n",
    "\n",
    "# nicer ordering\n",
    "df_compare = df_compare[[\n",
    "    \"model\",\"split\",\"best_threshold_from_val\",\n",
    "    \"precision\",\"recall\",\"f1\",\"fpr\",\"roc_auc\",\"pr_auc\"\n",
    "]].sort_values([\"model\",\"split\"])\n",
    "\n",
    "df_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "# delete big arrays + loaders + model\n",
    "del Xtr_seq, ytr_seq, Xva_seq, yva_seq, Xte_seq, yte_seq\n",
    "del train_loader, val_loader, test_loader\n",
    "del model, optimizer, criterion\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# if on GPU:\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
